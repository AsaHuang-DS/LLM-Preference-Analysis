{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7b8b630",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "\n",
    "### 1. Research Objective and Hypothesis\n",
    "\n",
    "**Primary Research Question:** Do users demonstrate distinct preferences for specific Large Language Models (LLMs) based on task type, and how do model characteristics (speed, cost, performance) influence these preferences?\n",
    "\n",
    "**Hypothesis:** Users exhibit statistically significant preferences for certain LLMs when performing specific tasks (e.g., coding, creative writing, data analysis). Furthermore, model characteristics such as response speed, operational cost, and benchmark performance metrics correlate with user preference patterns, with faster and more capable models being favored for technical tasks while cost-effective models are preferred for general conversation.\n",
    "\n",
    "**Research Sub-questions:**\n",
    "1. Which LLMs are most frequently preferred by users for coding-related tasks compared to creative or conversational tasks?\n",
    "2. Do model performance characteristics (speed, cost, benchmark scores) correlate with user preference rates?\n",
    "3. What task categories dominate user interactions with LLMs, and how does this vary across different models?\n",
    "4. Are there statistically significant differences in user satisfaction across LLM models when controlling for task type?\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Significance and Application\n",
    "\n",
    "**Relevance**:\n",
    "\n",
    "As artificial intelligence tools become increasingly integrated into professional and personal workflows, understanding user preferences and usage patterns is critical for multiple stakeholders:\n",
    "- **For AI Developers:** Insights into task-specific model performance can inform targeted optimization efforts and feature development priorities.\n",
    "- **For End Users:** Understanding which models excel at specific tasks can guide tool selection and improve productivity.\n",
    "- **For Researchers:** This analysis contributes to the growing body of knowledge on human-AI interaction patterns and user experience design.\n",
    "\n",
    "**Potential Applications:**\n",
    "\n",
    "The findings from this research could be applied to:\n",
    "1. **Product Development:** Guide AI companies in optimizing models for specific use cases and user needs.\n",
    "2. **User Interface Design:** Inform the development of recommendation systems that suggest appropriate models based on user tasks.\n",
    "3. **Educational Resources:** Create evidence-based guidance for users learning to work effectively with LLMs.\n",
    "4. **Market Analysis:** Provide insights into competitive positioning and market segmentation in the LLM space.\n",
    "\n",
    "**Future Investigation**:\n",
    "\n",
    "This work establishes a foundation for several future research directions:\n",
    "- Longitudinal studies tracking how user preferences evolve as models improve\n",
    "- Investigation of demographic factors influencing LLM preference patterns\n",
    "- Analysis of task complexity and its relationship to model selection\n",
    "- Exploration of multi-model workflows and when users switch between different LLMs\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Data Sources\n",
    "\n",
    "**Primary Dataset: Chatbot Arena Human Preferences**\n",
    "\n",
    "**Source:** [Hugging Face Repository](https://huggingface.co/datasets/lmarena-ai/arena-human-preference-55k) <br>\n",
    "**Access:** Publicly available via Hugging Face Datasets library\n",
    "\n",
    "**Dataset Characteristics:**\n",
    "- Volume: 55,000+ real-world user conversations\n",
    "- LLM Coverage: Over 70 state-of-the-art models including GPT-4, Claude 2, Llama 2, Gemini, Mistral, and others\n",
    "- Data Collection Period: Ongoing collection from Chatbot Arena platform\n",
    "- Key Features:\n",
    "    - Conversation prompts (user queries)\n",
    "    - Model responses from two competing models\n",
    "    - User vote (which model response was preferred)\n",
    "    - Model identifiers\n",
    "    - Timestamp information\n",
    "    - Conversation metadata\n",
    "\n",
    "**Preliminary Summary Statistics:**\n",
    "- Total conversations: 55,000+\n",
    "- Unique models represented: 70+\n",
    "- Data format: Structured JSON/CSV format\n",
    "- Average conversation length: To be determined during initial exploration\n",
    "- Vote distribution: To be analyzed for balance across models\n",
    "\n",
    "**Secondary Dataset: Large Language Models Comparison Dataset**\n",
    "\n",
    "**Source:** [Kaggle](https://www.kaggle.com/datasets/samayashar/large-language-models-comparison-dataset) <br>\n",
    "**Access:** Publicly available via Kaggle\n",
    "\n",
    "**Dataset Characteristics:**\n",
    "- Volume: Comprehensive coverage of major LLM models\n",
    "- Key Features:\n",
    "    - Model names and providers\n",
    "    - Performance metrics and benchmark scores\n",
    "    - Speed/latency measurements\n",
    "    - Cost per token information\n",
    "    - Model specifications (parameter count, architecture)\n",
    "    - Release dates\n",
    "\n",
    "**Integration Strategy:** The two datasets will be merged using model names as the common key, enriching user preference data with technical model characteristics to enable deeper analysis of the relationship between model attributes and user choices (could be difficult due to the differences in dataset sizes and possible unmatch \n",
    "model names).\n",
    "\n",
    "---\n",
    "\n",
    "### 4.Intended Analytical Approach\n",
    "\n",
    "**Techniques and Methods:**  \n",
    "- **Data Preparation:** pandas, Hugging Face datasets, data cleaning, and merging  \n",
    "- **Feature Engineering:** Conversation length, task classification (keyword-based), win rate per model  \n",
    "- **Exploratory Analysis:**  \n",
    "    - Distribution of preferences by model and task  \n",
    "    - Correlations between model characteristics (speed, cost) and user choices \n",
    "- **Statistical Testing:**  \n",
    "    - Chi-square tests for independence  \n",
    "    - ANOVA and t-tests for group comparisons  \n",
    "    - Correlation analysis between benchmarks and preferences  \n",
    "- **Visualization:** matplotlib, seaborn (bar charts, boxplots, heatmaps)  \n",
    "\n",
    "**Expected Output:**Cleaned dataset, descriptive and inferential statistics, and visualizations showing user preference trends and correlations with model performance.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2ffd8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f54cb4",
   "metadata": {},
   "source": [
    "### Data Exploration\n",
    "\n",
    "**Objective:** Understand the structure, quality, and characteristics of both datasets before cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d355d27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57477 rows × 9 columns\n",
      "200 rows × 15 columns\n"
     ]
    }
   ],
   "source": [
    "# Load Chatbot Arena dataset\n",
    "df_arena = pd.read_csv('../data/raw/chatbot_arena.csv')\n",
    "print(df_arena.shape[0], \"rows ×\", df_arena.shape[1], \"columns\")\n",
    "\n",
    "# Load Kaggle dataset (update filename if different)\n",
    "df_kaggle = pd.read_csv('../data/raw/llm_comparison_dataset.csv')\n",
    "print(df_kaggle.shape[0], \"rows ×\", df_kaggle.shape[1], \"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ae4780",
   "metadata": {},
   "source": [
    "### Inspect Arena Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4aa059fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in Arena Dataset: \n",
      "['id', 'model_a', 'model_b', 'prompt', 'response_a', 'response_b', 'winner_model_a', 'winner_model_b', 'winner_tie']\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns in Arena Dataset: \")\n",
    "print(df_arena.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b8e02517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30192</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[\"Is it morally right to try to have a certain...</td>\n",
       "      <td>[\"The question of whether it is morally right ...</td>\n",
       "      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53567</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[\"What is the difference between marriage lice...</td>\n",
       "      <td>[\"A marriage license is a legal document that ...</td>\n",
       "      <td>[\"A marriage license and a marriage certificat...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65089</td>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>mistral-medium</td>\n",
       "      <td>[\"explain function calling. how would you call...</td>\n",
       "      <td>[\"Function calling is the process of invoking ...</td>\n",
       "      <td>[\"Function calling is the process of invoking ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96401</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>mistral-7b-instruct</td>\n",
       "      <td>[\"How can I create a test set for a very rare ...</td>\n",
       "      <td>[\"Creating a test set for a very rare category...</td>\n",
       "      <td>[\"When building a classifier for a very rare c...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198779</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-3.5-turbo-0314</td>\n",
       "      <td>[\"What is the best way to travel from Tel-Aviv...</td>\n",
       "      <td>[\"The best way to travel from Tel Aviv to Jeru...</td>\n",
       "      <td>[\"The best way to travel from Tel-Aviv to Jeru...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id             model_a              model_b  \\\n",
       "0   30192  gpt-4-1106-preview           gpt-4-0613   \n",
       "1   53567           koala-13b           gpt-4-0613   \n",
       "2   65089  gpt-3.5-turbo-0613       mistral-medium   \n",
       "3   96401    llama-2-13b-chat  mistral-7b-instruct   \n",
       "4  198779           koala-13b   gpt-3.5-turbo-0314   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  [\"Is it morally right to try to have a certain...   \n",
       "1  [\"What is the difference between marriage lice...   \n",
       "2  [\"explain function calling. how would you call...   \n",
       "3  [\"How can I create a test set for a very rare ...   \n",
       "4  [\"What is the best way to travel from Tel-Aviv...   \n",
       "\n",
       "                                          response_a  \\\n",
       "0  [\"The question of whether it is morally right ...   \n",
       "1  [\"A marriage license is a legal document that ...   \n",
       "2  [\"Function calling is the process of invoking ...   \n",
       "3  [\"Creating a test set for a very rare category...   \n",
       "4  [\"The best way to travel from Tel Aviv to Jeru...   \n",
       "\n",
       "                                          response_b  winner_model_a  \\\n",
       "0  [\"As an AI, I don't have personal beliefs or o...               1   \n",
       "1  [\"A marriage license and a marriage certificat...               0   \n",
       "2  [\"Function calling is the process of invoking ...               0   \n",
       "3  [\"When building a classifier for a very rare c...               1   \n",
       "4  [\"The best way to travel from Tel-Aviv to Jeru...               0   \n",
       "\n",
       "   winner_model_b  winner_tie  \n",
       "0               0           0  \n",
       "1               1           0  \n",
       "2               0           1  \n",
       "3               0           0  \n",
       "4               1           0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_arena.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "882d8d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 57477 entries, 0 to 57476\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   id              57477 non-null  int64 \n",
      " 1   model_a         57477 non-null  object\n",
      " 2   model_b         57477 non-null  object\n",
      " 3   prompt          57477 non-null  object\n",
      " 4   response_a      57477 non-null  object\n",
      " 5   response_b      57477 non-null  object\n",
      " 6   winner_model_a  57477 non-null  int64 \n",
      " 7   winner_model_b  57477 non-null  int64 \n",
      " 8   winner_tie      57477 non-null  int64 \n",
      "dtypes: int64(4), object(5)\n",
      "memory usage: 3.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_arena.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b4de3e",
   "metadata": {},
   "source": [
    "### Inspect Kaggle Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a141be6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in Kaggle Dataset: \n",
      "['Model', 'Provider', 'Context Window', 'Speed (tokens/sec)', 'Latency (sec)', 'Benchmark (MMLU)', 'Benchmark (Chatbot Arena)', 'Open-Source', 'Price / Million Tokens', 'Training Dataset Size', 'Compute Power', 'Energy Efficiency', 'Quality Rating', 'Speed Rating', 'Price Rating']\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns in Kaggle Dataset: \")\n",
    "print(df_kaggle.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "64728202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Provider</th>\n",
       "      <th>Context Window</th>\n",
       "      <th>Speed (tokens/sec)</th>\n",
       "      <th>Latency (sec)</th>\n",
       "      <th>Benchmark (MMLU)</th>\n",
       "      <th>Benchmark (Chatbot Arena)</th>\n",
       "      <th>Open-Source</th>\n",
       "      <th>Price / Million Tokens</th>\n",
       "      <th>Training Dataset Size</th>\n",
       "      <th>Compute Power</th>\n",
       "      <th>Energy Efficiency</th>\n",
       "      <th>Quality Rating</th>\n",
       "      <th>Speed Rating</th>\n",
       "      <th>Price Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DeepSeek-4</td>\n",
       "      <td>Deepseek</td>\n",
       "      <td>128000</td>\n",
       "      <td>95</td>\n",
       "      <td>2.74</td>\n",
       "      <td>85</td>\n",
       "      <td>1143</td>\n",
       "      <td>1</td>\n",
       "      <td>18.81</td>\n",
       "      <td>760952565</td>\n",
       "      <td>13</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Llama-8</td>\n",
       "      <td>Meta AI</td>\n",
       "      <td>300000</td>\n",
       "      <td>284</td>\n",
       "      <td>3.21</td>\n",
       "      <td>71</td>\n",
       "      <td>1390</td>\n",
       "      <td>1</td>\n",
       "      <td>3.98</td>\n",
       "      <td>22891342</td>\n",
       "      <td>22</td>\n",
       "      <td>2.07</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Llama-5</td>\n",
       "      <td>Meta AI</td>\n",
       "      <td>300000</td>\n",
       "      <td>225</td>\n",
       "      <td>2.95</td>\n",
       "      <td>85</td>\n",
       "      <td>1406</td>\n",
       "      <td>0</td>\n",
       "      <td>1.02</td>\n",
       "      <td>827422145</td>\n",
       "      <td>21</td>\n",
       "      <td>0.95</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DeepSeek-3</td>\n",
       "      <td>Deepseek</td>\n",
       "      <td>2000000</td>\n",
       "      <td>242</td>\n",
       "      <td>12.89</td>\n",
       "      <td>72</td>\n",
       "      <td>1264</td>\n",
       "      <td>1</td>\n",
       "      <td>27.63</td>\n",
       "      <td>694305632</td>\n",
       "      <td>86</td>\n",
       "      <td>3.51</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DeepSeek-8</td>\n",
       "      <td>Deepseek</td>\n",
       "      <td>1000000</td>\n",
       "      <td>71</td>\n",
       "      <td>3.80</td>\n",
       "      <td>77</td>\n",
       "      <td>1381</td>\n",
       "      <td>1</td>\n",
       "      <td>18.52</td>\n",
       "      <td>378552278</td>\n",
       "      <td>92</td>\n",
       "      <td>1.80</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Model  Provider  Context Window  Speed (tokens/sec)  Latency (sec)  \\\n",
       "0  DeepSeek-4  Deepseek          128000                  95           2.74   \n",
       "1     Llama-8   Meta AI          300000                 284           3.21   \n",
       "2     Llama-5   Meta AI          300000                 225           2.95   \n",
       "3  DeepSeek-3  Deepseek         2000000                 242          12.89   \n",
       "4  DeepSeek-8  Deepseek         1000000                  71           3.80   \n",
       "\n",
       "   Benchmark (MMLU)  Benchmark (Chatbot Arena)  Open-Source  \\\n",
       "0                85                       1143            1   \n",
       "1                71                       1390            1   \n",
       "2                85                       1406            0   \n",
       "3                72                       1264            1   \n",
       "4                77                       1381            1   \n",
       "\n",
       "   Price / Million Tokens  Training Dataset Size  Compute Power  \\\n",
       "0                   18.81              760952565             13   \n",
       "1                    3.98               22891342             22   \n",
       "2                    1.02              827422145             21   \n",
       "3                   27.63              694305632             86   \n",
       "4                   18.52              378552278             92   \n",
       "\n",
       "   Energy Efficiency  Quality Rating  Speed Rating  Price Rating  \n",
       "0               0.50               2             2             3  \n",
       "1               2.07               1             3             3  \n",
       "2               0.95               2             3             2  \n",
       "3               3.51               1             3             3  \n",
       "4               1.80               2             2             3  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kaggle.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "48e6496c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 15 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Model                      200 non-null    object \n",
      " 1   Provider                   200 non-null    object \n",
      " 2   Context Window             200 non-null    int64  \n",
      " 3   Speed (tokens/sec)         200 non-null    int64  \n",
      " 4   Latency (sec)              200 non-null    float64\n",
      " 5   Benchmark (MMLU)           200 non-null    int64  \n",
      " 6   Benchmark (Chatbot Arena)  200 non-null    int64  \n",
      " 7   Open-Source                200 non-null    int64  \n",
      " 8   Price / Million Tokens     200 non-null    float64\n",
      " 9   Training Dataset Size      200 non-null    int64  \n",
      " 10  Compute Power              200 non-null    int64  \n",
      " 11  Energy Efficiency          200 non-null    float64\n",
      " 12  Quality Rating             200 non-null    int64  \n",
      " 13  Speed Rating               200 non-null    int64  \n",
      " 14  Price Rating               200 non-null    int64  \n",
      "dtypes: float64(3), int64(10), object(2)\n",
      "memory usage: 23.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_kaggle.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6edb95",
   "metadata": {},
   "source": [
    "### Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8a35c7e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.747700e+04</td>\n",
       "      <td>57477.000000</td>\n",
       "      <td>57477.000000</td>\n",
       "      <td>57477.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.142564e+09</td>\n",
       "      <td>0.349079</td>\n",
       "      <td>0.341911</td>\n",
       "      <td>0.309011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.238327e+09</td>\n",
       "      <td>0.476683</td>\n",
       "      <td>0.474354</td>\n",
       "      <td>0.462090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.019200e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.071821e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.133658e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.211645e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.294947e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  winner_model_a  winner_model_b    winner_tie\n",
       "count  5.747700e+04    57477.000000    57477.000000  57477.000000\n",
       "mean   2.142564e+09        0.349079        0.341911      0.309011\n",
       "std    1.238327e+09        0.476683        0.474354      0.462090\n",
       "min    3.019200e+04        0.000000        0.000000      0.000000\n",
       "25%    1.071821e+09        0.000000        0.000000      0.000000\n",
       "50%    2.133658e+09        0.000000        0.000000      0.000000\n",
       "75%    3.211645e+09        1.000000        1.000000      1.000000\n",
       "max    4.294947e+09        1.000000        1.000000      1.000000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Arena - Numerical\n",
    "df_arena.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a083c0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>57477</td>\n",
       "      <td>57477</td>\n",
       "      <td>57477</td>\n",
       "      <td>57477</td>\n",
       "      <td>57477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>51734</td>\n",
       "      <td>56566</td>\n",
       "      <td>56609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>[\"Answer the following statements with \\\"Agree...</td>\n",
       "      <td>[\"Hello! How can I assist you today?\"]</td>\n",
       "      <td>[\"Hello! How can I assist you today?\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3678</td>\n",
       "      <td>3709</td>\n",
       "      <td>101</td>\n",
       "      <td>109</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model_a             model_b  \\\n",
       "count                57477               57477   \n",
       "unique                  64                  64   \n",
       "top     gpt-4-1106-preview  gpt-4-1106-preview   \n",
       "freq                  3678                3709   \n",
       "\n",
       "                                                   prompt  \\\n",
       "count                                               57477   \n",
       "unique                                              51734   \n",
       "top     [\"Answer the following statements with \\\"Agree...   \n",
       "freq                                                  101   \n",
       "\n",
       "                                    response_a  \\\n",
       "count                                    57477   \n",
       "unique                                   56566   \n",
       "top     [\"Hello! How can I assist you today?\"]   \n",
       "freq                                       109   \n",
       "\n",
       "                                    response_b  \n",
       "count                                    57477  \n",
       "unique                                   56609  \n",
       "top     [\"Hello! How can I assist you today?\"]  \n",
       "freq                                       100  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Arena - Categorical\n",
    "df_arena.describe(include=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c9f7f7a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context Window</th>\n",
       "      <th>Speed (tokens/sec)</th>\n",
       "      <th>Latency (sec)</th>\n",
       "      <th>Benchmark (MMLU)</th>\n",
       "      <th>Benchmark (Chatbot Arena)</th>\n",
       "      <th>Open-Source</th>\n",
       "      <th>Price / Million Tokens</th>\n",
       "      <th>Training Dataset Size</th>\n",
       "      <th>Compute Power</th>\n",
       "      <th>Energy Efficiency</th>\n",
       "      <th>Quality Rating</th>\n",
       "      <th>Speed Rating</th>\n",
       "      <th>Price Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.000000e+02</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>2.000000e+02</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.371800e+05</td>\n",
       "      <td>163.240000</td>\n",
       "      <td>9.358750</td>\n",
       "      <td>77.945000</td>\n",
       "      <td>1192.960000</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>14.475200</td>\n",
       "      <td>4.902643e+08</td>\n",
       "      <td>46.915000</td>\n",
       "      <td>2.519100</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>2.275000</td>\n",
       "      <td>2.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.909439e+05</td>\n",
       "      <td>79.188106</td>\n",
       "      <td>5.489481</td>\n",
       "      <td>10.182356</td>\n",
       "      <td>174.649767</td>\n",
       "      <td>0.501154</td>\n",
       "      <td>8.890484</td>\n",
       "      <td>2.747544e+08</td>\n",
       "      <td>28.408679</td>\n",
       "      <td>1.458241</td>\n",
       "      <td>0.802008</td>\n",
       "      <td>0.625565</td>\n",
       "      <td>0.303911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.280000e+05</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>902.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>2.012584e+06</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000e+05</td>\n",
       "      <td>93.750000</td>\n",
       "      <td>4.265000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>1043.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.090000</td>\n",
       "      <td>2.622976e+08</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.150000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.560000e+05</td>\n",
       "      <td>165.500000</td>\n",
       "      <td>8.820000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1200.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.660000</td>\n",
       "      <td>5.002494e+08</td>\n",
       "      <td>43.500000</td>\n",
       "      <td>2.525000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>236.000000</td>\n",
       "      <td>14.035000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>1343.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.515000</td>\n",
       "      <td>7.210857e+08</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>3.807500</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000e+06</td>\n",
       "      <td>294.000000</td>\n",
       "      <td>19.800000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>1493.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>29.890000</td>\n",
       "      <td>9.844345e+08</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>4.980000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Context Window  Speed (tokens/sec)  Latency (sec)  Benchmark (MMLU)  \\\n",
       "count    2.000000e+02          200.000000     200.000000        200.000000   \n",
       "mean     6.371800e+05          163.240000       9.358750         77.945000   \n",
       "std      6.909439e+05           79.188106       5.489481         10.182356   \n",
       "min      1.280000e+05           20.000000       0.600000         60.000000   \n",
       "25%      2.000000e+05           93.750000       4.265000         69.000000   \n",
       "50%      2.560000e+05          165.500000       8.820000         80.000000   \n",
       "75%      1.000000e+06          236.000000      14.035000         87.000000   \n",
       "max      2.000000e+06          294.000000      19.800000         94.000000   \n",
       "\n",
       "       Benchmark (Chatbot Arena)  Open-Source  Price / Million Tokens  \\\n",
       "count                 200.000000   200.000000              200.000000   \n",
       "mean                 1192.960000     0.490000               14.475200   \n",
       "std                   174.649767     0.501154                8.890484   \n",
       "min                   902.000000     0.000000                0.200000   \n",
       "25%                  1043.250000     0.000000                6.090000   \n",
       "50%                  1200.500000     0.000000               14.660000   \n",
       "75%                  1343.750000     1.000000               21.515000   \n",
       "max                  1493.000000     1.000000               29.890000   \n",
       "\n",
       "       Training Dataset Size  Compute Power  Energy Efficiency  \\\n",
       "count           2.000000e+02     200.000000         200.000000   \n",
       "mean            4.902643e+08      46.915000           2.519100   \n",
       "std             2.747544e+08      28.408679           1.458241   \n",
       "min             2.012584e+06       2.000000           0.150000   \n",
       "25%             2.622976e+08      22.000000           1.150000   \n",
       "50%             5.002494e+08      43.500000           2.525000   \n",
       "75%             7.210857e+08      72.000000           3.807500   \n",
       "max             9.844345e+08      99.000000           4.980000   \n",
       "\n",
       "       Quality Rating  Speed Rating  Price Rating  \n",
       "count      200.000000    200.000000    200.000000  \n",
       "mean         1.900000      2.275000      2.910000  \n",
       "std          0.802008      0.625565      0.303911  \n",
       "min          1.000000      1.000000      1.000000  \n",
       "25%          1.000000      2.000000      3.000000  \n",
       "50%          2.000000      2.000000      3.000000  \n",
       "75%          3.000000      3.000000      3.000000  \n",
       "max          3.000000      3.000000      3.000000  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Kaggle - Numerical\n",
    "df_kaggle.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b07b08c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Provider</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>70</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Command-9</td>\n",
       "      <td>Cohere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model Provider\n",
       "count         200      200\n",
       "unique         70        8\n",
       "top     Command-9   Cohere\n",
       "freq            8       34"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Kaggle - Categorical\n",
    "df_kaggle.describe(include=['object'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef04a30",
   "metadata": {},
   "source": [
    "### Missing Values Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "93772ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Count</th>\n",
       "      <th>Missing %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Missing Count, Missing %]\n",
       "Index: []"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Arena missing values\n",
    "missing_arena = df_arena.isnull().sum()\n",
    "missing_pct = (missing_arena / len(df_arena) * 100).round(2)\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_arena, \n",
    "    'Missing %': missing_pct\n",
    "    }).sort_values('Missing %', ascending=False)\n",
    "\n",
    "# Only show columns with missing values\n",
    "missing_df[missing_df['Missing Count'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8c4f0f56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Count</th>\n",
       "      <th>Missing %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Missing Count, Missing %]\n",
       "Index: []"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Kaggle missing values\n",
    "missing_kaggle = df_kaggle.isnull().sum()\n",
    "missing_pct_k = (missing_kaggle / len(df_kaggle) * 100).round(2)\n",
    "missing_df_k = pd.DataFrame({\n",
    "    'Missing Count': missing_kaggle, \n",
    "    'Missing %': missing_pct_k\n",
    "    }).sort_values('Missing %', ascending=False)\n",
    "\n",
    "# Only show columns with missing values\n",
    "missing_df_k[missing_df_k['Missing Count'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8be84e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
